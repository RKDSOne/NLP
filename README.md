# NLP: Coding Jurafsky & Martin (2009)

* **J&M_01**: Regex, (N/D)FSA, FST, Edit Distance, Auto Correction.
* **J&M_02**: N-Gram Language Model, Smoothing, POS (Simple Bi/Trigram HMM w/ Viterbi Algorithm, 1-3 Gram Deleted Interpolation)
* **J&M_03**: HMM (Forward Algorithm, Viterbi Algorithm, Forward-Backward Algorithm), EM Algorithm.
* **J&M_04**: MaxEnt Classification, MEMM, CRF.
* **J&M_05**: Speech Recognition. (ON HOLD)
* **J&M_06**: Chomsky Normal Form (CNF), CKY Algorithm, Earley Algorithm.
* **J&M_07**: Statistical Parsing.

### NOTE:
* Code is under active development and refinement (updated daily at this time), comments are most welcome! 
* Some codes are repeated in various sections for better section-independence. 
* Naming takes the verbose approach in an effort to make concepts and pipelines absolutely clear and readable. 
